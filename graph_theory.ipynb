{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_dict(nodes, edges):\n",
    "    G = {node: [] for node in nodes}\n",
    "    for edge in edges:\n",
    "        node1, node2 = edge[0], edge[1]\n",
    "        G[node1].append(node2)\n",
    "        G[node2].append(node1)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directed_graph_dict(nodes, edges):\n",
    "    G = {node: [] for node in nodes}\n",
    "    for edge in edges:\n",
    "        node1, node2 = edge[0], edge[1]\n",
    "        G[node1].append(node2)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs_recursive(G, start, dis=None, clos=None, par=None):\n",
    "    if dis is None:\n",
    "        dis = []\n",
    "        clos = []\n",
    "        par = dict()\n",
    "    dis.append(start)\n",
    "    for v in G[start]:\n",
    "        if v not in dis:\n",
    "            par[v] = start\n",
    "            dfs_recursive(G, v, dis, clos, par)\n",
    "    clos.append(start)\n",
    "    return {\"discovered\": dis, \"closed\": clos, \"parents\": par}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs_iterative(G, start, dis=set(), clos=[], par=dict(), comp = set()):\n",
    "    stack = [(start, \"open\")]\n",
    "    while stack:\n",
    "        v, state = stack.pop()\n",
    "        if state == \"open\":\n",
    "            if v in dis:\n",
    "                continue\n",
    "            dis.add(v)\n",
    "            comp.add(v)\n",
    "            stack.append((v, \"close\"))\n",
    "            chi = [i for i in G[v] if i not in dis][::-1]\n",
    "            for i in chi:\n",
    "                par[i] = v\n",
    "                stack.append((i, \"open\"))\n",
    "        else:\n",
    "            clos.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs_full(G, start=list(G.keys())[0]):\n",
    "    dis = set()\n",
    "    clos = []\n",
    "    par = dict()\n",
    "    comp = set()\n",
    "    all_comp = set()\n",
    "    dfs_iterative(G, start, dis, clos, par, comp)\n",
    "    comp = frozenset(comp)\n",
    "    all_comp.add(comp)\n",
    "    for v in G:\n",
    "        if v not in dis:\n",
    "            comp = set()\n",
    "            dfs_iterative(G, v, dis, clos, par, comp)\n",
    "            comp = frozenset(comp)\n",
    "            all_comp.add(comp)\n",
    "    return {\"discovered\": dis, \"closed\": clos, \"parents\": par, \"comps\": all_comp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_g(G):\n",
    "    G_T = {v: [] for v in G.keys()}\n",
    "    for v in G.keys():\n",
    "        children = G[v]\n",
    "        for j in children:\n",
    "            G_T[j].append(v)\n",
    "    return G_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scc(G):\n",
    "    initial_dfs = dfs_full(G)\n",
    "    G_ord = dict()\n",
    "    for v in initial_dfs[\"closed\"][::-1]:\n",
    "        G_ord[v] = G[v]\n",
    "    G_T = inverse_g(G_ord)\n",
    "    second_dfs = dfs_full(G_T, start = list(G_T.keys())[0])\n",
    "    sccs = second_dfs[\"comps\"]\n",
    "    return sccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts(G, start):  # Topological sorting using DFS\n",
    "    sorted_graph = dict()\n",
    "    res = dfs_full(G, start)\n",
    "    sort = res[\"closed\"][::-1]\n",
    "    for i in sort:\n",
    "        sorted_graph[i] = G[i]\n",
    "    return sorted_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs_iterative(G, start = list(G.keys())[0], dis = set()):\n",
    "    queue = [start]\n",
    "    dis.add(start)\n",
    "    temp_G_traversed = dict()\n",
    "    for node in G:\n",
    "        temp_G_traversed[node] = []\n",
    "    while queue:\n",
    "        local_root = queue[0]\n",
    "        for v in G[local_root]:\n",
    "            if v in dis:\n",
    "                continue\n",
    "            queue.append(v)\n",
    "            dis.add(v)\n",
    "            temp_G_traversed[local_root].append(v)\n",
    "        G_traversed = {i: temp_G_traversed[i] for i in temp_G_traversed if temp_G_traversed[i]}\n",
    "        queue = queue[1:]\n",
    "    return {\"Discovered\": dis, \"Traversed Graph\": G_traversed}\n",
    "\n",
    "def bfs_full(G, start=list(G.keys())[0]):\n",
    "    dis = set()\n",
    "    G_traversed = dict()\n",
    "    temp_result = bfs_iterative(G, start, dis)\n",
    "    dis = temp_result[\"Discovered\"]\n",
    "    G_traversed = temp_result[\"Traversed Graph\"]\n",
    "    for v in G:\n",
    "        if v in dis:\n",
    "            continue\n",
    "        temp_result = bfs_iterative(G, v, dis)\n",
    "        dis = temp_result[\"Discovered\"]\n",
    "        G_traversed = temp_result[\"Traversed Graph\"] | G_traversed\n",
    "    G_traversed = G_traversed | {j: [] for j in G if j not in G_traversed}\n",
    "    return {\"Discovered\": dis, \"Traversed Graph\": G_traversed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fundamental_cycles(G, start):\n",
    "    bfs_result = bfs_full(G, start)\n",
    "    G_traversed = bfs_result[\"Traversed Graph\"]\n",
    "    fundamental_cycle_edges = {\n",
    "        i: [j for j in G[i] if j not in G_traversed[i]] for i in G\n",
    "    }\n",
    "    return fundamental_cycle_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_G_to_edge_list(G_w):\n",
    "    edge_list = []\n",
    "    for v in G_w:\n",
    "        for in_node in G_w[v]:\n",
    "            temp_in_node_list = list(in_node)\n",
    "            temp_in_node_list.insert(0, v)\n",
    "            temp_edge_check = temp_in_node_list[:]\n",
    "            temp_edge_check[0], temp_edge_check[1] = temp_edge_check[1], temp_edge_check[0]\n",
    "            if temp_edge_check not in edge_list:\n",
    "                edge_list.append(temp_in_node_list)\n",
    "    return edge_list\n",
    "\n",
    "def get_edge_weight(edge):\n",
    "    return(edge[2])\n",
    "\n",
    "def union(x, y, disjoint_sets):\n",
    "    set_x = find(x, disjoint_sets)\n",
    "    set_y = find(y, disjoint_sets)\n",
    "    if set_x != set_y:\n",
    "        disjoint_sets.remove(set_x)\n",
    "        disjoint_sets.remove(set_y)\n",
    "        disjoint_sets.append(set_x.union(set_y))\n",
    "    return disjoint_sets\n",
    "\n",
    "def find(x, disjoint_sets):\n",
    "    for s in disjoint_sets:\n",
    "        if x in s:\n",
    "            return s\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def kruskal_algorithm(G_w):\n",
    "    G_edge_list = weighted_G_to_edge_list(G_w)\n",
    "    G_edge_list.sort(key = get_edge_weight)\n",
    "    min_span_tree = []\n",
    "    node_disjoint_sets = [{i} for i in G_w]\n",
    "    while len(node_disjoint_sets) > 1:\n",
    "        for edge in G_edge_list:\n",
    "            node1_set = find(edge[0], node_disjoint_sets)\n",
    "            node2_set = find(edge[1], node_disjoint_sets)\n",
    "            if node1_set != node2_set:\n",
    "                node_disjoint_sets.remove(node1_set)\n",
    "                node_disjoint_sets.remove(node2_set)\n",
    "                node_disjoint_sets.append(node1_set.union(node2_set))\n",
    "                min_span_tree.append(edge)\n",
    "    G_span_tree = {v: [] for v in G_w}\n",
    "    for edge in min_span_tree:\n",
    "        G_span_tree[edge[0]].append((edge[1], edge[2]))\n",
    "        G_span_tree[edge[1]].append((edge[0], edge[2]))\n",
    "    return G_span_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "\n",
    "def get_edge_weight(edge):\n",
    "    return(edge[1])\n",
    "\n",
    "\n",
    "def prim_algorithm(G_w, start_node):\n",
    "    G_w_cp = copy.deepcopy(G_w)\n",
    "    G_span_tree = {i: [] for i in G_w_cp}\n",
    "    tree_nodes = {start_node}\n",
    "    \n",
    "    if start_node not in G_w_cp:\n",
    "        return \"Starting note non-existent in the graph adjacency list.\"\n",
    "    for v in G_w_cp:\n",
    "        G_w_cp[v].sort(key = get_edge_weight)\n",
    "\n",
    "    for node in G_w_cp:\n",
    "        G_w_cp[node] = [edge for edge in G_w_cp[node] if edge[0] != start_node]\n",
    "\n",
    "    while len(tree_nodes) < len(G_w_cp):\n",
    "        considered_edges = []\n",
    "        for tree_node in tree_nodes:\n",
    "            temp_edge = list(G_w_cp[tree_node][0])\n",
    "            temp_edge.append(tree_node)\n",
    "            considered_edges.append(temp_edge)\n",
    "        considered_edges.sort(key = get_edge_weight)\n",
    "        add_edge = considered_edges[0]\n",
    "        add_node = add_edge[0]\n",
    "        src_node = add_edge[2]\n",
    "        G_span_tree[src_node].append((add_node, add_edge[1]))\n",
    "        G_span_tree[add_node].append((src_node, add_edge[1]))\n",
    "        tree_nodes.add(add_node)\n",
    "        for node in G_w_cp:\n",
    "            G_w_cp[node] = [edge for edge in G_w_cp[node] if edge[0] != add_node]\n",
    "\n",
    "    return G_span_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bellman_ford_algorithm(G_d_w, source_node):\n",
    "    control_dict = {v: [[], float(\"inf\"), None] for v in G_d_w} # Initiate a control dictionary noting the path to v, distance and predecessor node\n",
    "    control_dict[source_node] = [[source_node], 0, source_node] # Initiate source node to have path of distance 0 (from itself to itself)\n",
    "    discovered_nodes = {source_node}\n",
    "    for i in range(0, len(G_d_w)):\n",
    "        for from_node in G_d_w:\n",
    "            for edge in G_d_w[from_node]:\n",
    "                to_node = edge[0]\n",
    "                if control_dict[from_node][1] + edge[1] < control_dict[to_node][1]:\n",
    "                    new_path = control_dict[from_node][0][:]\n",
    "                    new_path.append(to_node)\n",
    "                    control_dict[to_node][0] = new_path\n",
    "                    control_dict[to_node][1] = control_dict[from_node][1] + edge[1]\n",
    "                    control_dict[to_node][2] = from_node\n",
    "    for from_node in G_d_w:\n",
    "        for edge in G_d_w[from_node]:\n",
    "            to_node = edge[0]\n",
    "            if control_dict[from_node][1] + edge[1] < control_dict[to_node][1]:\n",
    "                print(f\"A negative weight cycle exists with {from_node}\")\n",
    "                path_with_negative_cycle = control_dict[from_node][0]\n",
    "                cycle_node = None\n",
    "                cycle_path = [from_node]\n",
    "                while cycle_node != from_node:\n",
    "                    cycle_node = path_with_negative_cycle[:-1][-1]\n",
    "                    path_with_negative_cycle = path_with_negative_cycle[:-1]\n",
    "                    cycle_path.append(cycle_node)\n",
    "                cycle_path = cycle_path[:0:-1]\n",
    "                raise ValueError(f\"Graph contains a negative cycle {cycle_path}\")\n",
    "    return control_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'newkey', 12]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictt = {1: \"\", 12: \"qw\"}\n",
    "dictt.keys()\n",
    "sett = set()\n",
    "\n",
    "sett.update(list(dictt.keys()))\n",
    "sett\n",
    "dictt[\"newkey\"] = []\n",
    "dictt\n",
    "sett = set()\n",
    "sett.update(list(dictt.keys()))\n",
    "list(sett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def initiate_s_t(G_d_c): # As defined in a transport network, initiate source and target vertices.\n",
    "    G_d_c_copy = copy.deepcopy(G_d_c)\n",
    "    G_d_c_copy['s'] = dict()\n",
    "    non_source_nodes = set()\n",
    "    for node in G_d_c_copy:\n",
    "        non_source_nodes.update(list(G_d_c_copy[node].keys()))\n",
    "    source_nodes = list({node for node in G_d_c_copy if node not in non_source_nodes and node != 's'})\n",
    "    for node in source_nodes:\n",
    "        G_d_c_copy['s'][node] = {'cap': float('inf'), 'flow': 0}\n",
    "    target_nodes = [node for node in G_d_c_copy if G_d_c_copy[node] == {}]\n",
    "    for node in target_nodes:\n",
    "        G_d_c_copy[node]['t'] = {'cap': float('inf'), 'flow': 0}\n",
    "    G_d_c_copy['t'] = dict()\n",
    "    return G_d_c_copy\n",
    "    \n",
    "\n",
    "def make_reverse_edges(G_d_c_copy): # For Edmonds-Karp algorithm in a transport network with capacities, reverse edges should be made with capacities of 0 and flow of 0 for residual capacities further.\n",
    "    for s_node in G_d_c_copy:\n",
    "        for t_node in G_d_c_copy[s_node]:\n",
    "            if s_node not in G_d_c_copy[t_node]:\n",
    "                G_d_c_copy[t_node][s_node] = {'cap': 0, 'flow': 0}\n",
    "    return G_d_c_copy\n",
    "\n",
    "def bfs_iterative_ek(G, start = list(G.keys())[0], dis = set(), paths = [[list(G.keys())[0]]]):\n",
    "    queue = [start]\n",
    "    dis.add(start)\n",
    "    temp_G_traversed = dict()\n",
    "    for node in G:\n",
    "        temp_G_traversed[node] = []\n",
    "    \n",
    "    while queue:\n",
    "        local_root = queue[0]\n",
    "        path_curr = [copy.deepcopy(path) for path in paths if path[-1] == local_root]\n",
    "        for v in G[local_root]:\n",
    "            if v in dis or G[local_root][v]['cap'] <= G[local_root][v]['flow']:\n",
    "                continue\n",
    "            path_curr_on_v = copy.deepcopy(path_curr)\n",
    "            path_curr_on_v[0].append(v)\n",
    "            paths.append(path_curr_on_v[0])\n",
    "            paths = [path[:] for path in paths if path[-1] != local_root]\n",
    "            queue.append(v)\n",
    "            dis.add(v)\n",
    "            temp_G_traversed[local_root].append(v)\n",
    "        G_traversed = {i: temp_G_traversed[i] for i in temp_G_traversed if temp_G_traversed[i]}\n",
    "        queue = queue[1:]\n",
    "    return {\"Discovered\": dis, \"Traversed Graph\": G_traversed, \"paths\": paths}\n",
    "\n",
    "def bfs_full_ek(G, start=list(G.keys())[0]):\n",
    "    dis = set()\n",
    "    G_traversed = dict()\n",
    "    paths = [[start]]\n",
    "    temp_result = bfs_iterative_ek(G, start, dis, paths)\n",
    "    dis = temp_result[\"Discovered\"]\n",
    "    G_traversed = temp_result[\"Traversed Graph\"]\n",
    "    paths = temp_result['paths']\n",
    "    G_traversed = G_traversed | {j: [] for j in G if j not in G_traversed}\n",
    "    return {\"Discovered\": dis, \"Traversed Graph\": G_traversed, \"paths\": paths}\n",
    "\n",
    "def edmonds_karp_algorithm(G_d_c):\n",
    "    G_s_t = initiate_s_t(G_d_c)\n",
    "    G_s_t_r = make_reverse_edges(G_s_t)\n",
    "    print(G_s_t_r)\n",
    "    min_df = float('inf')\n",
    "    flow = 0\n",
    "    used_path = 1\n",
    "    while used_path: \n",
    "        bfs_to_t = bfs_full_ek(G_s_t_r, start = 's')\n",
    "        local_paths = copy.deepcopy(bfs_to_t['paths'])\n",
    "        used_path = next((path for path in local_paths if 't' in path), None)\n",
    "        if used_path:\n",
    "            for i in range(0, len(used_path) - 1):\n",
    "                u, v = used_path[i], used_path[i + 1]\n",
    "                edge = G_s_t_r[u][v]\n",
    "\n",
    "                df = edge['cap'] - edge['flow']\n",
    "\n",
    "                min_df = min(min_df, df)\n",
    "\n",
    "            for i in range(0, len(used_path) - 1):\n",
    "                u, v = used_path[i], used_path[i + 1]\n",
    "                edge = G_s_t_r[u][v]\n",
    "                rev_edge = G_s_t_r[v][u]\n",
    "\n",
    "                edge['flow'] += min_df\n",
    "                rev_edge['flow'] -= min_df\n",
    "\n",
    "            flow += min_df\n",
    "    \n",
    "    return {'transport_network': G_s_t_r, 'flow': flow}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def gale_shapley_algorithm(G_pref):\n",
    "    G_pref_copy = copy.deepcopy(G_pref)\n",
    "    pairs = set()\n",
    "    while len(pairs) != len(G_pref_copy[\"callers\"]):\n",
    "        for caller in G_pref_copy[\"callers\"]:\n",
    "            receiver = G_pref_copy[\"callers\"][caller][0]\n",
    "            current_rec_pair = next((pair for pair in pairs if receiver == pair[1]), None)\n",
    "            if not current_rec_pair:\n",
    "                pairs.add((caller, receiver))\n",
    "            elif G_pref_copy[\"rec\"][receiver].index(caller) < G_pref_copy[\"rec\"][receiver].index(current_rec_pair[0]):\n",
    "                pairs.remove(current_rec_pair)\n",
    "                pairs.add((caller, receiver))\n",
    "            else:\n",
    "                pass\n",
    "            G_pref_copy[\"callers\"][caller] = G_pref_copy[\"callers\"][caller][1:]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {5: [7], 6: [5], 7: [6], 1: [2, 3], 2: [1, 3], 3: [1, 2, 4], 4: [5, 3]}\n",
    "G = {1: [2, 3], 3: [1, 2, 4], 2: [1, 3], 4: [3], 5: [6, 4], 6: [7], 7: [5]}\n",
    "G = {\"a\": [\"b\", \"c\"], \"r\": [\"a\", \"c\"], \"b\": [], \"c\": []}\n",
    "G = {1: [2], 2: [3], 3: [1]}\n",
    "G = {1: []}\n",
    "G = {1: [2], 2: [3], 3: [1], 4: [5], 5:[]}\n",
    "G_d_c = {1: {2: {'cap': 20, 'flow': 0}, 50: {'cap': 999, 'flow': 0}},\n",
    "          2: {3: {'cap': 10, 'flow': 0}, 4: {'cap': 5, 'flow': 0}},\n",
    "            3: {},\n",
    "              4: {},\n",
    "              50: {}\n",
    "              }\n",
    "G_w = {1: [(2, 0)], 2: [(3, 500)], 3: [(1, 2)]}\n",
    "G_w = {1: [(2, 0), (3, 2)], 2: [(3, 500), (1, 0)], 3: [(1, 2), (2, 500)]}\n",
    "G_d_w = {1: [(2, 1)], 2: [(3, 2)], 3: [(4, 2)], 4: [(5, 3)], 5: []}\n",
    "G_pref = {\"callers\": {\"a\": [2, 3, 1], \"b\": [2, 1, 3], \"c\": [3, 2, 1]}, \"rec\": {1: [\"c\", \"b\", \"a\"], 2: [\"b\", \"a\", \"c\"], 3: [\"c\", \"b\", \"a\"]}}\n",
    "G_edge_list = [(1, 2, 0), (2, 3, 500), (3, 1, 2)]\n",
    "root = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dfs_r = dfs_recursive(G, root)\n",
    "res_dfs_f = dfs_full(G, root)\n",
    "print(res_dfs_r)\n",
    "print(res_dfs_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topological_sort = ts(G, root)\n",
    "print(topological_sort)\n",
    "strong_components = scc(G)\n",
    "print(strong_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_bfs_f = bfs_full(G, root)\n",
    "print(res_bfs_f)\n",
    "res_fund_cycl = fundamental_cycles(G, root)\n",
    "print(res_fund_cycl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [(2, 0), (3, 2)], 2: [(1, 0)], 3: [(1, 2)]}\n"
     ]
    }
   ],
   "source": [
    "res_kruskal = kruskal_algorithm(G_w)\n",
    "print(res_kruskal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [(2, 0), (3, 2)], 2: [(1, 0)], 3: [(1, 2)]}\n"
     ]
    }
   ],
   "source": [
    "res_prim = prim_algorithm(G_w, 1)\n",
    "print(res_prim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [[1], 0, 1], 2: [[1, 2], 1, 1], 3: [[1, 2, 3], 3, 2], 4: [[1, 2, 3, 4], 5, 3], 5: [[1, 2, 3, 4, 5], 8, 4]}\n"
     ]
    }
   ],
   "source": [
    "res_bellman_ford = bellman_ford_algorithm(G_d_w, 1)\n",
    "print(res_bellman_ford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ek = edmonds_karp_algorithm(G_d_c)\n",
    "print(res_ek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gs = gale_shapley_algorithm(G_pref)\n",
    "print(res_gs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
